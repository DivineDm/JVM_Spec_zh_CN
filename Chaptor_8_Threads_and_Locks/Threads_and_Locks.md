# 第八章 线程和锁

本章介绍一些底层的基本操作(action)，这些操作将让我们能更好的看清Java虚拟机和主存是如何交互的。

## 8.1 术语和框架定义

变量在程序中随处可见，变量不仅包含类变量(class本身也是一种变量)和实例变量(class对象实例变量)，也包含集合中的元素等变量。变量被存储在主存(main memory)中，并被进程中的所有线程共享。对于一个线程T，他拥有的参数和变量，别的线程是无法引用到的，因此我们不用关心T拥有的参数和变量是保存在主存中，还是线程栈(working memory)中。

>**Note:** 这里对于线程参数，我理解原文想表达的是这个参数从引用关系来讲，只从属于T。因此对于主线程将一个变量v同时通过构造函数传递给T1和T2，从而形成T1和T2互相影响v的场景不是作者想表达的场景

每一个线程都有自己的线程栈，线程栈中保存线程执行use和assign操作(action)需要用到的程序变量副本，该副本是从主存中复制而来的。当一个线程执行一个程序时，线程操作这些变量副本，并不直接写主存。主存中保存所有变量的真身(master copy)，也就是说线程操作的是栈中保存的变量的分身，当然分身也可以通过一些操作覆盖真身，后面会讲到。在真身(主存中的变量)和分身(栈中的变量)的相互复制之中，需要满足一些规则。

主存中的每一个变量都有一个锁(lock)，线程可以尝试获取变量的锁。

在本章中，每一个线程可以执行如下操作use, assign, load, store, lock, unlock。主存子系统(main memeory subsystem)可以执行read, write, lock, unlock这些操作。以上的每一个操作都是原子的。

use、assign操作与线程执行引擎和线程栈紧密相关。lock和unlock操作与线程执行引擎和主存紧密相关。但是对于数据在主存和栈两个地方的来回传递，是松耦合的。当一个数据要从主存中拷贝到栈中时，两个操作必须发生：主存必须执行一个read操作，在之后的某一个时刻，对应的一个load操作必须发生在栈上。当一个数据要从栈拷贝到主存时，同样必须发生两个操作：栈上必须执行一个store操作，之后的某一个时刻，主存必须执行一个write操作。主存和栈区每一条指令执行时，都会有一个取指的运输时间(transit time，和CPU流水线结构相关)，并且不同的数据处理流(transaction)的这个时间也会不同。因此针对某一个线程对不同变量的操作，操作的初始时间构成的顺序，不同线程看到的也会有所不同。但是，不管是主存代替线程执行还是线程本身自己执行，执行的操作顺序(operation order)一定是一样的。

>**Note:** 这里我理解的是，比如对于线程T1，操作两个变量a和b，顺序是先a后b，但是操作a的变量指令取指运送时间长，后面的b反而短。当这种现象发生时，线程T1依然以为是先a后b，但是对于另一个线程T2来看，好像是b先于a发生了操作

每一个线程从程序的语义角度来看，都可以看成是由一系列的use, assign, lock, unlock构成的。在Java虚拟机规范中，线程还需要附加执行一些load, store, read和write操作，从而去满足一些条件和限制，这个后面会介绍到。如果虚拟机的实现者和程序的编写者遵循了这些限制，那么JVM规范可以保证，数据可以安全可信赖的在主存和栈中来回交换赋值。这些JVM规范是良设计的，他们被设计的足够严谨来保证数据可信赖，同时又留有余地给硬件和软件的设计者，可以利用注册、队列、缓存来充分的提供程序运行速度和吞吐量。

下面是各个操作的详细定义

* 线程执行的use操作，可以将栈中的变量传递给线程的执行引擎。每当一个线程执行一个需要用到变量去计算的虚指令(虚拟机指令)时，use操作都会被执行
* 线程执行的assign操作，可以将线程执行引擎中的变量传递给栈。每当一个线程执行一个需要复制给变量的虚指令时，assign操作都会被执行
* 主存执行的read操作，可以将主存中的变量内容发射(transmit)给线程栈，之后load操作会用到read发射出的变量值。(很多中文书这里都讲错了，read操作并没有完成主存到栈，数据复制的全过程，就像从北京到上海，read只是离开了北京而已，load才是到了上海。道理很简单，因为对于计算机系统而言，没有指令能做到主存到主存(栈也是在memory中)的转移，都需要一次主存到寄存器，再从寄存器到主存的过程)
* 线程执行的load操作，将read操作发射的变量保存到栈中
* 线程执行的store操作，将栈中的变量内容发射出去，目标是主存
* 主存执行的write操作，将store操作发射出来的变量值写入到主存
* lock操作(需要线程和主存紧密协作，同步完成)，线程尝试获得某一个锁
* unlock操作(需要线程和主存紧密协作，同步完成)，线程尝试释放某一个锁

因此，可以看出，线程和变量的交互是由一系列的use, assign, load, store构成的，主存来配合为每一个load操作执行一个read操作，为每一个store操作执行一个write操作。线程和锁的交互就是一系列的lock和unlock。所有这些对变量的操作和锁的操作，统一构成了线程展现给外界的所有行为。

## 8.2 执行顺序和一致性

执行顺序的规则限制了可能会发生的事件集合的顺序。在各个操作关系中，有四个基本规则限制，他们是

* 每一个线程执行的操作(action)都是有序的。也就是说，对于一个线程执行的任意两个操作来说，一定有一个操作先于另一个操作发生
* 对于主存而言，对每一个相同变量执行的操作都是有序的。也就是说，对同一个变量主存执行的任意两个操作，一定有一个操作先于另一个操作发生
* 对于主存而言，对每一个锁的操作都是有序的。也就是说，对于同一个锁，主存执行的任意两个操作，一定有一个操作先于另一个操作发生
* 不允许有连续的相同操作(It is not permitted for an action to follow itself)

最后一个限制看上去有一点多余，但是实际上是有必要单独并明确声明的。如果没有最后一条规则，那么就有可能在多线程的场景下，存在一组操作集合，他们先后顺序满足前三条规则，但是存在连续的相同action。这里单独列出这条性质，可以避免出现这种情况。

线程间不会互相直接交互，他们需要通过主存来实现。线程的操作集合和主存的操作集合，两者需要满足下面三个限制

* 一组线程和主存构成的lock和unlock必须是成对的
* 线程的load操作必须和主存的read操作一一对应，并且load操作必须在read操作之后
* 线程的store操作必须和主存的write操作一一对应，并且store操作必须在write操作之前

下面的大部分规则都是在以上的规则基础上，进一步限制了一些操作的执行顺序。这些规则，可能限制了某一个操作必须发生在某些操作之前或者之后。需要注意的是，这些操作顺序是可推演的: 如果操作A必须先于操作B，操作B必须先于操作C，那么操作A一定是先于操作C的。程序员需要知道的是，操作的顺序只受限于规则限制。如果没有规则、或者没有规则的某种组合，来限制操作A和操作B的顺序，那么JVM的实现者对于操作A和操作B的顺序是随意的，某一个JVM实现版本可能是A先于B，另一个JVM实现版本可能是B先于A，甚至B和A并发/并行，这些都是合法的。这种自由对于实现高性能JVM是非常重要的。当然，一个JVM的实现版本也没有要求必须要充分利用这种自由。

在下面的规则限制中，短语“B必须介入A和C”，表示操作B必须在A之后、C之前发生。

## 8.3 变量的规则

我们定义T表示一个线程，V表示一个变量。T执行过程中对V有如下限制

* 根据标准执行模型(standard execution model)，T对V执行use或者assign操作，当且仅当T在执行到需要用到use或者assign指令的代码时，才允许执行use和assign操作。举个例子，当线程执行到一个这样的时刻，此时V作为`+`操作符的操作数时，一个针对V的use操作将会发生。又比如V作为`=`操作符的做操作数时，一个针对V的assign操作将会发生。给定一个线程，所有的use和assign操作，必须严格按照程序定义的顺序来依序发生。如果下面的限制禁止线程选择use作为下一个操作，那么T可能有必要先选择执行一个load操作来推动程序继续往下发展。
* T对V执行的store必须介于T对V的assign和随后的T对V的load(非正式：线程不允许漏掉最近的一次assign操作)
* T对V执行的assign必须介于T对V的load/store和随后的T对V的store(非正式：线程不允许随意将栈区变量值同步到主存中)
* 在T创建成功后，对V执行use/store之前必须先执行assign/load(非正式：线程的栈区初始状态是空的)
* 在V创建成功后，每一个线程对V执行use/store之前必须先执行assign/load(非正式：任何一个变量创建成功后，初始时总是只存在于主存中，并不存在于栈中)

只要满足了8.3, 8.6, 8.7中的规则限制，任意线程对任意变量在任意时刻都可以执行load和store操作，这完全看JVM实现者的心情。

主存执行的read和write操作也有规则限制，如下

* T对V执行的load操作，都必须有一个对应的read，并且load写入栈的值必须是对应read发射出的值
* T对V执行的store操作，都必须有一个对应的write操作，并且write写入主存的值必须是对应的store发射出的值
* 假设A是T对V执行的load/store，P是主存对V执行的read/write。相似的，假设B是T(同一个线程)对V执行的load/store，Q是主存对V执行的read/write。如果A先于B发生，那么P一定先于Q发生(非正式：针对某一个变量，主存执行操作的先后顺序，和这些操作匹配的线程操作执行顺序是相同的)

注意，上面的最后一条规则，仅适用于某一个线程针对同一个变量的操作而言。另外，如果这个变量是volatile修饰，那么它还会有更严格的限制，8.7会讲到这方面的内容。

## 8.4 double、long型变量的非原子性

如果一个double/long型变量(长整形,64bit)没有声明为volatile，那么针对这个变量的load,store,read,write操作都实现为好像是两个32bit变量的对应操作。在满足规则限制下，对V执行上面每一个的操作，都会执行两遍，每次操作32bit。需要说明的是，将64bit变量底层编码为两个32bit的变量体(32bit quantities)，并且这两个32bit的先后顺序都不是Java语言规范定义的。

这需要注意，因为对double/long变量的read/write操作，被分裂成了两个32bit变量的read/write操作，并且这两个操作之间有时间间隙，别的操作在规则允许的条件下也可能会插入到这两个操作之间。更进一步，如果两个线程分别将两个不同的值并发复制给同一个非volatile的double/long变量，那么随后的use操作可能取到的数与初始化的两个数都不相等，可能是两个数的32bit的某一种混合，这需要视JVM的实现细节来决定。

是否需要将64bit变量的上述操作实现为原子操作，关于这一点并没有要求。但是，我们鼓励JVM的开发者实现成原子操作。分割变量bit值，主要是因为现在流行的32位的微处理器架构并不能很好的支持64位变量的内存原子操作。如果我们能够将任意变量的内存操作都实现为原子操作，那无疑是非常便于开发者编写易于理解的代码，现在关于这一点的定义复杂化，还是处于对当前硬件架构的一种妥协让步。在将来，64Bit变量的非原子性操作也许有可能会被改善。但是，此时程序员还是非常有必要认识到对于共享的double/long变量(多线程访问)操作，我们需要进行多线程同步。

## 8.5 锁的规则

我们定义T表示一个线程，L表示一个锁。T执行过程中对L的操作有如下限制

* T可以持有L，当且仅当除了T之外的所有线程集合*S*之前对L执行的unlock操作数和lock操作数相等(非正式：在任一时刻，一个锁只能被一个线程持有，进一步，一个已经持有L的T，还可以继续多次进行lock操作，增加加锁的深度。只有当执行了对应深度的unlock操作之后，这个线程才算真正释放了锁L)
* T可以对L执行unlock，当且仅当T对L执行的unlock次数小于lock次数(非正式：T不允许在未持有L的情况下执行unlock操作)

对于锁L，所有线程对L的lock/unlock组成一个串行的序列，并且这个序列和每一个线程对L的lock/unlock是一致的。

## 8.6 锁与变量交互的规则

定义T代表任意线程，V表示任意变量，L表示任意锁。一下是T操作V和L的限制

* `assign -> store -> write -> unlock` T对V的store必须介于T对V的assign和T对L的unlock；此外，主存对应store的write操作必须先于unlock(非正式：如果线程要执行一次unlock操作，那么必须将之前已经assign过的数据同步写回主存中) ，可以这么理解，如果你已经通过加锁实现同步来完成某些变量的更新，那么针对这些assign过的更新变量理应同步会主存，因为不会有线程跟你竞争
* `lock -> /read -> assign/load -> store/use` 对V的assign/load必须介于T对L的lock和T对V的use/store之间；此外，如果T对V的操作是load，那么与之对应的read操作必须跟在lock之后。(非正式：一个lock操作就好像要求线程在assign或者load之后，必须将栈中的变量flush掉。注意，针对lock，并没有要求flush的变量必须写回到主存) 

## 8.7 volatile变量的规则

如果一个变量被声明为volatile类型，那么线程会被追加要求满足如下的规则限制，其中T表示一个线程，V和W表示一个volatile变量

* `read -> load -next> use` T允许对V执行use操作，当且仅当T对V的上一个操作是load，并且，T允许对V执行load操作，当且仅当T对V的下一个操作是use。在这种情形下，我们称use操作与read操作是关联(associated)的
* `assign -next> store -> write` T允许对V执行store操作，当且仅当T对V的上一个操作是assign，并且，T允许对V执行assign操作，当且仅当T对V的下一个操作是store。在这种情形下，我们称assign操作与write操作是关联的
* 用A表示T对V执行的use/assign，F表示与A对应的load/store，P表示与F对应的read/write。相似的，我们有针对T之于变量W的定义B、G、Q。如果A先于B发生，那么P一定先于Q发生(非正式：主存对volatile变量执行的对应操作read/write顺序，与线程执行操作load/store的顺序是一致的)

> 在JSR-133(Java Specification Requests，Java规范提案)中，对volatile的要求作了进一步的限制，要求在对volatile变量进行读写时，其前后的指令在一定条件下不允许重排序(包含编译重排序和CPU重排序)，条件如下
>
> * 如果是一条对volatile变量进行写操作的代码，那么该代码前面的任何代码都不能与这个写操作交换顺序。
> * 如果是一条对volatile变量进行读取的操作代码，那么这个代码后面的所有操作都不能与这一条读指令交换位置
> 
> 可以这么理解，对volatile变量赋值之前的代码happen-before这个赋值操作。对volatile变量读取的代码happen-before之后的代码

## 8.8 前置的预测型store操作

如果一个变量没有声明为volatile类型，那么在8.7节定义的规则限制里关于store条件将被放宽松，store操作发生的时间允许早于变量为volatile时所要求的时间点。也就是说，在volatile时，store必须发生在assign之后，但是对于非volatile变量，允许store发生在assign之前，也就是说非volatile变量即使更新了，也不一定会立刻发射给主存。放宽限制的目的是允许编译器进行一些指令重排序(code rearrangement，译者觉得这里的指令重排序主要强调的是store前置)从而优化代码，这样的宽松能够使那些做了很好的同步工作的程序保持逻辑语义不变，但是对于哪些并没有做好充分同步工作的程序，他们的内存操作可能会发生混乱，导致数据错误

> 如何理解上面最后的一段话呢？我的理解是在有lock的情况下，多线程程序只有一个线程能够持有锁，在lock和unlock之间，即使有重排序，在unlock之前也会完成同步更新回主存(包含write操作)，从而实现逻辑语义不变，见8.6第一条限制，unlock前所有assigned变量都会完成同步写回主存。然而，如果没有做同步，即lock/unlock，那么一个线程的store/assign更新后，变量最新值也许并没有同步回主存(因为不知道write会发生在什么时刻)，此时其他线程从主存来读取这个变量时，依然是旧的值，从而导致数据错误

让我们假设如果T对V的store操作，发生在T对V的assign之后，就像上一节规定的那样，并且T对V的下一个操作不是assign/load。那么这个store操作将会把assign操作更新的最新变量值发射给主存。重新回到本节讨论的问题点，我们确实允许非volatile变量的store早于assign发生，只要满足以下条件

* store虽然先发生了，但assign随后一定会发生(注意，这里强调了一定，并不是应该。即，如果store之后，assign前，出现了异常，导致assign没有发生，这样的情况store不能前置)
* 前置的store和assign之间，不能有lock操作
* 前置的store和assign之间，不能对V进行load(这条限制译者没太看明白，如果哪位了解，希望能跟进)
* 前置的store和assign之间，不能有对V的其他store操作
* 前置的store发射给主存的V的值，必须是随后的assign操作将会更新的目标值

上述的最后一条限制非常重要，正是因为这一条限制，我们才称这样的前置store操作为预测型store操作，因为他已经提前知道了随后assign操作计算出来的目标值。这种提前预判是可能的，在现代的工业实践中，优化后的代码将会提前计算这样的值，前提是这样的计算不会产生副作用或者导致异常。然后提前将变量值发射回主存(比如，在进入一个循环之前，提前计划更新主存里的这个变量)，并且将提前计算好的变量值保存在寄存器中，在接下来的循环中会被用到。

## 8.9 讨论

任何锁与变量之间的关联都是非常纯粹的基于上面的限制。任何lock操作从概念上来看都是将栈区的变量flush掉，任何unlock操作会将所有assign过的变量写回到主存中。对象和类，他们和锁的关联也是非常纯粹的基于上面的限制。比如，在一些应用中，经常会看到对一个对象加锁，然后读取这个实例的变量值，一个简单的synchronized方法就可以很方便的做到这一点。在另外一些应用中，也有单独顶一个锁变量，然后对这个锁变量加锁，从而线程安全的读取某些海量数据集。

如果一个线程要用到一个多线程共享的变量，那么这个线程应该先持有一个锁，执行一些操作*S*，随后释放这个锁。在这种情境下，操作*S*用到的变量将是从主存同步过来的最新值，如果*S*里存在assign操作，那么assign操作后的值会在unlock前同步写回到主存中。通过锁的互斥规则，我们能够保证多线程共享变量可以安全的在主存和线程栈中来回赋值计算。

volatile的规则要求一个线程对volatile变量的use/assign操作都会触发一次主存的读/写访问，并且主存的读写访问顺序，和线程代码执行逻辑的语义顺序是一致的(8.7的第三条规则)。需要注意的是，如果是非volatile变量，这样的顺序一致性不能够得到保证(线程中的变量操作会有重排序发生)。

## 8.10 例子：交换函数的多种可能性

## 8.11 例子：乱序写

## 8.12 线程

## 8.13 锁和同步

## 8.14 等待集，通知

